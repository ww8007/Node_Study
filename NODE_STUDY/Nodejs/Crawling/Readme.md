# Crawling

# 목차

1. Crawling 개요
1. 배송위치 추적
1. Pupppeteer -> python 셀레니움과 비슷

정적인 데이터 -> 네이버 id, pw -> 로그인 상태에서 게시물 가져오는 경우
chrome브라우저에서 소스를 가져옴

### 순서

1. URL에서 HTML을 가져옴
1. 내가 원하는 부분을 가져옴

- 패키지
  1. request
     url로 호출 후 데이터를 가져옴
  2. cheerio
     jQuery 방식으로 DOM을 가져와서 데이터를 정제

* m1칩이라 12.0버전을 지원하지 않아서 다른 버전을 사용하도록 함

### 요청하기

request.js 에 url 을 입력하여서 받아올 수 있음

### 배송위치 추적

대한통운 송장번호를 넣으면 위치를 받아오도록 설정

request와 cheerio를 통해서 받아오게 함

request promise를 통해서 한 줄 한 줄 받아올 수 있게 함

- 유니크한 클래스나 아이디를 통해서 불러오는 것이 관건
  -> 원하는 정보만 받아오게 할 수 있도록 하는 것이 목표

* trim() 좌우 공백 문자 잘라서 사용
  -> 상품인수를 받아올 수 있는 방법을 여러군데에 사용하면 된다.

* 반복해서 데이터를 받아올 수 있도록 설정하는 것이 목표이다.
  표 형식으로 되어있기 때문에 반복을 받아오면 된다.

table이 4개 씩 들어오므로 이를 4개씩 반복해서 temp에 쌓고 이를 json화 시켜서 res에 쏴줌

app.set('json spaces',2);
-> 좀 더 보기 쉽게 만들어줌

- 지금은 정적으로 화면에 나오는 것만 받아올 수 밖에 없다.
  다음 시간에 액션에 대한 명령을 내려 줄 수 있는 것을 해보도록 함
  click하는 액션 같은 경우가 존재하는 경우

### Puppeteer

동적 브라우저를 띄워서 크롤링
